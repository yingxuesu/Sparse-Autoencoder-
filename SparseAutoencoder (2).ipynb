{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparseAutoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feiAhU_KJTJm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header = None)\n",
        "data.columns = ['Label', 'Alcohol', 'Malic Acid', 'Ash', 'Alcalinity of ash ', 'Magnesium', 'Total phenols', 'Flavanoids' , 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Na3FGB7pYiI",
        "outputId": "a2cf5365-8c7f-4e7f-c934-ef947e333de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.51861254, -0.5622498 ,  0.23205254, ...,  0.36217728,\n",
              "         1.84791957,  1.01300893],\n",
              "       [ 0.24628963, -0.49941338, -0.82799632, ...,  0.40605066,\n",
              "         1.1134493 ,  0.96524152],\n",
              "       [ 0.19687903,  0.02123125,  1.10933436, ...,  0.31830389,\n",
              "         0.78858745,  1.39514818],\n",
              "       ...,\n",
              "       [ 0.33275817,  1.74474449, -0.38935541, ..., -1.61212515,\n",
              "        -1.48544548,  0.28057537],\n",
              "       [ 0.20923168,  0.22769377,  0.01273209, ..., -1.56825176,\n",
              "        -1.40069891,  0.29649784],\n",
              "       [ 1.39508604,  1.58316512,  1.36520822, ..., -1.52437837,\n",
              "        -1.42894777, -0.59516041]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "things = data.values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "### MLP regression\n",
        "X = things[:, 1:14]\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set the input shape\n",
        "input_shape = (13,)\n",
        "print(f'Feature shape: {input_shape}')\n",
        "\n",
        "def regularizer(x):\n",
        "    q= tf.reduce_mean(x)\n",
        "    p=tf.constant(0.1)\n",
        "    c=tf.constant(200.1)\n",
        "    return -c*p*tf.math.log(q)-c*(1-p)*tf.math.log(1-q)\n",
        "\n",
        "input = tf.keras.Input(shape=input_shape)\n",
        "encoded = Dense(80, activation='sigmoid',\n",
        "                activity_regularizer=regularizer)(input)\n",
        "decoded = Dense(13, activation='linear')(encoded)\n",
        "\n",
        "autoencoder = tf.keras.Model(input, decoded)\n",
        "encoder=tf.keras.Model(input,encoded)\n",
        "\n",
        "\n",
        "optimizer= tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# Instantiate a loss function.\n",
        "loss =tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "batch_size=20\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Prepare the validat"
      ],
      "metadata": {
        "id": "FPkbdjz5JWcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regularizer(tf.constant([1.1,2.1,3.8]))"
      ],
      "metadata": {
        "id": "e4anOouNM60o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def GradNorm(grads):\n",
        "  w=grads[0].numpy()\n",
        "  w=w.flatten()\n",
        "  for i in range(1,4):\n",
        "    w1=grads[i].numpy()\n",
        "    w=np.append(w, w1.flatten())\n",
        "\n",
        "  return np.linalg.norm(w)\n",
        "\n",
        "import time\n",
        "  \n",
        "    \n",
        "epochs = 500\n",
        "trainMSE=[]\n",
        "testMSE=[]\n",
        "NormGrad=[]\n",
        "time1=time.time()\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, X_train))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(20)\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        \n",
        "\n",
        "\n",
        "        # Open a GradientTape to record the operations run\n",
        "        # during the forward pass, which enables auto-differentiation.\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # Run the forward pass of the layer.\n",
        "            # The operations that the layer applies\n",
        "            # to its inputs are going to be recorded\n",
        "            # on the GradientTape.\n",
        "            logits = autoencoder(x_batch_train, training=True)\n",
        "            enc=encoder(x_batch_train)\n",
        "              # Logits for this minibatch\n",
        "            logits2 = autoencoder(X_test, training=False)\n",
        "\n",
        "            # Compute the loss value for this minibatch.\n",
        "            loss_value = loss(y_batch_train, logits)\n",
        "            #print(loss_value.numpy())\n",
        "            trainMSE.append(loss_value.numpy())\n",
        "            loss_value2 = loss(X_test, logits2)\n",
        "            testMSE.append(loss_value2.numpy())\n",
        "\n",
        "\n",
        "\n",
        "        # Use the gradient tape to automatically retrieve\n",
        "        # the gradients of the trainable variables with respect to the loss.\n",
        "        grads = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
        "        NormGrad.append(GradNorm(grads))\n",
        "        \n",
        "\n",
        "        # Run one step of gradient descent by updating\n",
        "        # the value of the variables to minimize the loss.\n",
        "        optimizer.apply_gradients(zip(grads, autoencoder.trainable_weights))\n",
        "        #Weight=model.getweights()\n",
        "\n",
        "\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 5 == 0:\n",
        "          print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "          print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
        "    \n",
        "time2=time.time()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKNqRKZHPdqP",
        "outputId": "ae382325-331d-4148-b644-c9bc6331251d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 1.4336\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 1.0737\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 1.1657\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.9979\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 2\n",
            "Training loss (for one batch) at step 0: 1.0344\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.8954\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 3\n",
            "Training loss (for one batch) at step 0: 0.7829\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.7486\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 4\n",
            "Training loss (for one batch) at step 0: 0.7737\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.8774\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 5\n",
            "Training loss (for one batch) at step 0: 0.6960\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.9116\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 6\n",
            "Training loss (for one batch) at step 0: 0.6116\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.6760\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 7\n",
            "Training loss (for one batch) at step 0: 0.7412\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.5365\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 8\n",
            "Training loss (for one batch) at step 0: 0.5833\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.6363\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 9\n",
            "Training loss (for one batch) at step 0: 0.6318\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.5199\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 10\n",
            "Training loss (for one batch) at step 0: 0.5765\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.5129\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 11\n",
            "Training loss (for one batch) at step 0: 0.5428\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.5216\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 12\n",
            "Training loss (for one batch) at step 0: 0.4907\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.6096\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 13\n",
            "Training loss (for one batch) at step 0: 0.5977\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.4886\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 14\n",
            "Training loss (for one batch) at step 0: 0.4341\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3668\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 15\n",
            "Training loss (for one batch) at step 0: 0.4091\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.4873\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 16\n",
            "Training loss (for one batch) at step 0: 0.3908\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3862\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 17\n",
            "Training loss (for one batch) at step 0: 0.4052\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3246\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 18\n",
            "Training loss (for one batch) at step 0: 0.4176\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3895\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 19\n",
            "Training loss (for one batch) at step 0: 0.3872\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.4629\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 20\n",
            "Training loss (for one batch) at step 0: 0.3378\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3213\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 21\n",
            "Training loss (for one batch) at step 0: 0.2921\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3562\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 22\n",
            "Training loss (for one batch) at step 0: 0.3506\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2748\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 23\n",
            "Training loss (for one batch) at step 0: 0.3085\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2177\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 24\n",
            "Training loss (for one batch) at step 0: 0.2264\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.4778\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 25\n",
            "Training loss (for one batch) at step 0: 0.3488\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2872\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 26\n",
            "Training loss (for one batch) at step 0: 0.3681\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.3089\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 27\n",
            "Training loss (for one batch) at step 0: 0.2231\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2251\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 28\n",
            "Training loss (for one batch) at step 0: 0.1959\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2496\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 29\n",
            "Training loss (for one batch) at step 0: 0.2511\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2893\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 30\n",
            "Training loss (for one batch) at step 0: 0.2586\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2663\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 31\n",
            "Training loss (for one batch) at step 0: 0.2208\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2283\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 32\n",
            "Training loss (for one batch) at step 0: 0.2501\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2162\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 33\n",
            "Training loss (for one batch) at step 0: 0.2549\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1684\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 34\n",
            "Training loss (for one batch) at step 0: 0.1820\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1574\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 35\n",
            "Training loss (for one batch) at step 0: 0.1866\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.2193\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 36\n",
            "Training loss (for one batch) at step 0: 0.2091\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1909\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 37\n",
            "Training loss (for one batch) at step 0: 0.2548\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1949\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 38\n",
            "Training loss (for one batch) at step 0: 0.1336\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1491\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 39\n",
            "Training loss (for one batch) at step 0: 0.1727\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1666\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 40\n",
            "Training loss (for one batch) at step 0: 0.2088\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1426\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 41\n",
            "Training loss (for one batch) at step 0: 0.1417\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1862\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 42\n",
            "Training loss (for one batch) at step 0: 0.1681\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1424\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 43\n",
            "Training loss (for one batch) at step 0: 0.1668\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1222\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 44\n",
            "Training loss (for one batch) at step 0: 0.1438\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1583\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 45\n",
            "Training loss (for one batch) at step 0: 0.1521\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1259\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 46\n",
            "Training loss (for one batch) at step 0: 0.1272\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1259\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 47\n",
            "Training loss (for one batch) at step 0: 0.1094\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1469\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 48\n",
            "Training loss (for one batch) at step 0: 0.1465\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1084\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 49\n",
            "Training loss (for one batch) at step 0: 0.1416\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0923\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 50\n",
            "Training loss (for one batch) at step 0: 0.1235\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1124\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 51\n",
            "Training loss (for one batch) at step 0: 0.1198\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1284\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 52\n",
            "Training loss (for one batch) at step 0: 0.1095\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1405\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 53\n",
            "Training loss (for one batch) at step 0: 0.0805\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0843\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 54\n",
            "Training loss (for one batch) at step 0: 0.0894\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1203\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 55\n",
            "Training loss (for one batch) at step 0: 0.1178\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.1435\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 56\n",
            "Training loss (for one batch) at step 0: 0.0800\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0971\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 57\n",
            "Training loss (for one batch) at step 0: 0.0780\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0934\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 58\n",
            "Training loss (for one batch) at step 0: 0.0781\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0858\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 59\n",
            "Training loss (for one batch) at step 0: 0.0683\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0960\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 60\n",
            "Training loss (for one batch) at step 0: 0.0767\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0825\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 61\n",
            "Training loss (for one batch) at step 0: 0.0915\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0951\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 62\n",
            "Training loss (for one batch) at step 0: 0.0892\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0947\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 63\n",
            "Training loss (for one batch) at step 0: 0.0923\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0698\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 64\n",
            "Training loss (for one batch) at step 0: 0.0628\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0638\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 65\n",
            "Training loss (for one batch) at step 0: 0.0714\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0835\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 66\n",
            "Training loss (for one batch) at step 0: 0.0736\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0547\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 67\n",
            "Training loss (for one batch) at step 0: 0.0692\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0660\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 68\n",
            "Training loss (for one batch) at step 0: 0.0543\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0781\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 69\n",
            "Training loss (for one batch) at step 0: 0.0748\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0710\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 70\n",
            "Training loss (for one batch) at step 0: 0.0577\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0795\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 71\n",
            "Training loss (for one batch) at step 0: 0.0598\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0605\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 72\n",
            "Training loss (for one batch) at step 0: 0.0645\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0505\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 73\n",
            "Training loss (for one batch) at step 0: 0.0477\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0549\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 74\n",
            "Training loss (for one batch) at step 0: 0.0650\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0620\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 75\n",
            "Training loss (for one batch) at step 0: 0.0602\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0856\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 76\n",
            "Training loss (for one batch) at step 0: 0.0476\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0780\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 77\n",
            "Training loss (for one batch) at step 0: 0.0737\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0613\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 78\n",
            "Training loss (for one batch) at step 0: 0.0422\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0486\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 79\n",
            "Training loss (for one batch) at step 0: 0.0396\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0440\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 80\n",
            "Training loss (for one batch) at step 0: 0.0523\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0477\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 81\n",
            "Training loss (for one batch) at step 0: 0.0519\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0421\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 82\n",
            "Training loss (for one batch) at step 0: 0.0517\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0514\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 83\n",
            "Training loss (for one batch) at step 0: 0.0466\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0570\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 84\n",
            "Training loss (for one batch) at step 0: 0.0444\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0410\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 85\n",
            "Training loss (for one batch) at step 0: 0.0341\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0505\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 86\n",
            "Training loss (for one batch) at step 0: 0.0510\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0411\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 87\n",
            "Training loss (for one batch) at step 0: 0.0389\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0390\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 88\n",
            "Training loss (for one batch) at step 0: 0.0419\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0330\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 89\n",
            "Training loss (for one batch) at step 0: 0.0387\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0344\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 90\n",
            "Training loss (for one batch) at step 0: 0.0325\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0367\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 91\n",
            "Training loss (for one batch) at step 0: 0.0426\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0349\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 92\n",
            "Training loss (for one batch) at step 0: 0.0274\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0349\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 93\n",
            "Training loss (for one batch) at step 0: 0.0442\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0421\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 94\n",
            "Training loss (for one batch) at step 0: 0.0346\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0241\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 95\n",
            "Training loss (for one batch) at step 0: 0.0308\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0352\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 96\n",
            "Training loss (for one batch) at step 0: 0.0237\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0281\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 97\n",
            "Training loss (for one batch) at step 0: 0.0213\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0333\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 98\n",
            "Training loss (for one batch) at step 0: 0.0336\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0349\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 99\n",
            "Training loss (for one batch) at step 0: 0.0225\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0420\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 100\n",
            "Training loss (for one batch) at step 0: 0.0353\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0213\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 101\n",
            "Training loss (for one batch) at step 0: 0.0264\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0252\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 102\n",
            "Training loss (for one batch) at step 0: 0.0264\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0227\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 103\n",
            "Training loss (for one batch) at step 0: 0.0277\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0223\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 104\n",
            "Training loss (for one batch) at step 0: 0.0278\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0189\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 105\n",
            "Training loss (for one batch) at step 0: 0.0224\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0243\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 106\n",
            "Training loss (for one batch) at step 0: 0.0200\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0287\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 107\n",
            "Training loss (for one batch) at step 0: 0.0192\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0305\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 108\n",
            "Training loss (for one batch) at step 0: 0.0184\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0226\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 109\n",
            "Training loss (for one batch) at step 0: 0.0195\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0254\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 110\n",
            "Training loss (for one batch) at step 0: 0.0300\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0249\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 111\n",
            "Training loss (for one batch) at step 0: 0.0133\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0198\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 112\n",
            "Training loss (for one batch) at step 0: 0.0201\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0189\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 113\n",
            "Training loss (for one batch) at step 0: 0.0285\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0166\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 114\n",
            "Training loss (for one batch) at step 0: 0.0184\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0180\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 115\n",
            "Training loss (for one batch) at step 0: 0.0134\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0150\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 116\n",
            "Training loss (for one batch) at step 0: 0.0177\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0175\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 117\n",
            "Training loss (for one batch) at step 0: 0.0250\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0141\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 118\n",
            "Training loss (for one batch) at step 0: 0.0299\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0176\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 119\n",
            "Training loss (for one batch) at step 0: 0.0225\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0177\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 120\n",
            "Training loss (for one batch) at step 0: 0.0287\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0156\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 121\n",
            "Training loss (for one batch) at step 0: 0.0237\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0166\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 122\n",
            "Training loss (for one batch) at step 0: 0.0150\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0220\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 123\n",
            "Training loss (for one batch) at step 0: 0.0155\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0127\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 124\n",
            "Training loss (for one batch) at step 0: 0.0184\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0235\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 125\n",
            "Training loss (for one batch) at step 0: 0.0208\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0174\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 126\n",
            "Training loss (for one batch) at step 0: 0.0134\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0128\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 127\n",
            "Training loss (for one batch) at step 0: 0.0135\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0156\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 128\n",
            "Training loss (for one batch) at step 0: 0.0164\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0103\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 129\n",
            "Training loss (for one batch) at step 0: 0.0098\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0133\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 130\n",
            "Training loss (for one batch) at step 0: 0.0132\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0127\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 131\n",
            "Training loss (for one batch) at step 0: 0.0117\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0202\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 132\n",
            "Training loss (for one batch) at step 0: 0.0122\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0195\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 133\n",
            "Training loss (for one batch) at step 0: 0.0082\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0140\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 134\n",
            "Training loss (for one batch) at step 0: 0.0161\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0118\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 135\n",
            "Training loss (for one batch) at step 0: 0.0144\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0118\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 136\n",
            "Training loss (for one batch) at step 0: 0.0169\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0117\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 137\n",
            "Training loss (for one batch) at step 0: 0.0092\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0113\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 138\n",
            "Training loss (for one batch) at step 0: 0.0154\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0088\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 139\n",
            "Training loss (for one batch) at step 0: 0.0105\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0150\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 140\n",
            "Training loss (for one batch) at step 0: 0.0103\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0122\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 141\n",
            "Training loss (for one batch) at step 0: 0.0064\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0187\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 142\n",
            "Training loss (for one batch) at step 0: 0.0085\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0089\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 143\n",
            "Training loss (for one batch) at step 0: 0.0089\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0107\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 144\n",
            "Training loss (for one batch) at step 0: 0.0098\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0088\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 145\n",
            "Training loss (for one batch) at step 0: 0.0078\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0121\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 146\n",
            "Training loss (for one batch) at step 0: 0.0094\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0183\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 147\n",
            "Training loss (for one batch) at step 0: 0.0073\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0168\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 148\n",
            "Training loss (for one batch) at step 0: 0.0071\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0106\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 149\n",
            "Training loss (for one batch) at step 0: 0.0088\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0145\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 150\n",
            "Training loss (for one batch) at step 0: 0.0064\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0094\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 151\n",
            "Training loss (for one batch) at step 0: 0.0130\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0083\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 152\n",
            "Training loss (for one batch) at step 0: 0.0078\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0139\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 153\n",
            "Training loss (for one batch) at step 0: 0.0081\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0107\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 154\n",
            "Training loss (for one batch) at step 0: 0.0084\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0083\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 155\n",
            "Training loss (for one batch) at step 0: 0.0088\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0090\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 156\n",
            "Training loss (for one batch) at step 0: 0.0098\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0063\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 157\n",
            "Training loss (for one batch) at step 0: 0.0066\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0093\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 158\n",
            "Training loss (for one batch) at step 0: 0.0087\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0059\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 159\n",
            "Training loss (for one batch) at step 0: 0.0071\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0104\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 160\n",
            "Training loss (for one batch) at step 0: 0.0101\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0073\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 161\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0067\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 162\n",
            "Training loss (for one batch) at step 0: 0.0065\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0064\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 163\n",
            "Training loss (for one batch) at step 0: 0.0070\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0059\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 164\n",
            "Training loss (for one batch) at step 0: 0.0068\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0093\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 165\n",
            "Training loss (for one batch) at step 0: 0.0081\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0040\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 166\n",
            "Training loss (for one batch) at step 0: 0.0067\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 167\n",
            "Training loss (for one batch) at step 0: 0.0058\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0082\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 168\n",
            "Training loss (for one batch) at step 0: 0.0122\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0087\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 169\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0047\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 170\n",
            "Training loss (for one batch) at step 0: 0.0058\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0102\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 171\n",
            "Training loss (for one batch) at step 0: 0.0079\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0099\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 172\n",
            "Training loss (for one batch) at step 0: 0.0052\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 173\n",
            "Training loss (for one batch) at step 0: 0.0062\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 174\n",
            "Training loss (for one batch) at step 0: 0.0048\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0050\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 175\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 176\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 177\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0048\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 178\n",
            "Training loss (for one batch) at step 0: 0.0107\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0041\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 179\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0056\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 180\n",
            "Training loss (for one batch) at step 0: 0.0072\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 181\n",
            "Training loss (for one batch) at step 0: 0.0059\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0091\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 182\n",
            "Training loss (for one batch) at step 0: 0.0067\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0089\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 183\n",
            "Training loss (for one batch) at step 0: 0.0071\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0039\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 184\n",
            "Training loss (for one batch) at step 0: 0.0050\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0044\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 185\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0054\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 186\n",
            "Training loss (for one batch) at step 0: 0.0064\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0085\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 187\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0038\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 188\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0047\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 189\n",
            "Training loss (for one batch) at step 0: 0.0108\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 190\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 191\n",
            "Training loss (for one batch) at step 0: 0.0055\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0086\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 192\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 193\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0071\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 194\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0048\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 195\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0100\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 196\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 197\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 198\n",
            "Training loss (for one batch) at step 0: 0.0039\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0036\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 199\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0029\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 200\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0041\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 201\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0063\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 202\n",
            "Training loss (for one batch) at step 0: 0.0060\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0053\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 203\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0067\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 204\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0052\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 205\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 206\n",
            "Training loss (for one batch) at step 0: 0.0044\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0036\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 207\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0031\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 208\n",
            "Training loss (for one batch) at step 0: 0.0047\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0036\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 209\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 210\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 211\n",
            "Training loss (for one batch) at step 0: 0.0045\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0077\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 212\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0040\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 213\n",
            "Training loss (for one batch) at step 0: 0.0059\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0047\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 214\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 215\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 216\n",
            "Training loss (for one batch) at step 0: 0.0075\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 217\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0046\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 218\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 219\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0031\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 220\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 221\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0049\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 222\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 223\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0041\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 224\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0036\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 225\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0042\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 226\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 227\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 228\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0031\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 229\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 230\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 231\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0042\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 232\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 233\n",
            "Training loss (for one batch) at step 0: 0.0040\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 234\n",
            "Training loss (for one batch) at step 0: 0.0038\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0043\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 235\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0037\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 236\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 237\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 238\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 239\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0031\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 240\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0044\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 241\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 242\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 243\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 244\n",
            "Training loss (for one batch) at step 0: 0.0037\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 245\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0037\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 246\n",
            "Training loss (for one batch) at step 0: 0.0051\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 247\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0034\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 248\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 249\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0035\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 250\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 251\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 252\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 253\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0041\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 254\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 255\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 256\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 257\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0048\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 258\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 259\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 260\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 261\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 262\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 263\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 264\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 265\n",
            "Training loss (for one batch) at step 0: 0.0042\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 266\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 267\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 268\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 269\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 270\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0046\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 271\n",
            "Training loss (for one batch) at step 0: 0.0041\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 272\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 273\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0043\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 274\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0031\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 275\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 276\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 277\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 278\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 279\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 280\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 281\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 282\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0034\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 283\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 284\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 285\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 286\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0040\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 287\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0033\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 288\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 289\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 290\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 291\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 292\n",
            "Training loss (for one batch) at step 0: 0.0026\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 293\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 294\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 295\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 296\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 297\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0040\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 298\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 299\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 300\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0037\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 301\n",
            "Training loss (for one batch) at step 0: 0.0032\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 302\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 303\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0030\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 304\n",
            "Training loss (for one batch) at step 0: 0.0036\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 305\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 306\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 307\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 308\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 309\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0029\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 310\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 311\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 312\n",
            "Training loss (for one batch) at step 0: 0.0034\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 313\n",
            "Training loss (for one batch) at step 0: 0.0033\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 314\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0042\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 315\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 316\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 317\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 318\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 319\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 320\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0029\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 321\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 322\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 323\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0027\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 324\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 325\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 326\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 327\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 328\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 329\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0032\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 330\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 331\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 332\n",
            "Training loss (for one batch) at step 0: 0.0031\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 333\n",
            "Training loss (for one batch) at step 0: 0.0027\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 334\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 335\n",
            "Training loss (for one batch) at step 0: 0.0030\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 336\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 337\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0029\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 338\n",
            "Training loss (for one batch) at step 0: 0.0024\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0034\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 339\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 340\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 341\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 342\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 343\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 344\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 345\n",
            "Training loss (for one batch) at step 0: 0.0025\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 346\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 347\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 348\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 349\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 350\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 351\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 352\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 353\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 354\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 355\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 356\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 357\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 358\n",
            "Training loss (for one batch) at step 0: 0.0028\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 359\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 360\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 361\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 362\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 363\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 364\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 365\n",
            "Training loss (for one batch) at step 0: 0.0029\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 366\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 367\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 368\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0029\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 369\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 370\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 371\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 372\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 373\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 374\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 375\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 376\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 377\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 378\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0025\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 379\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 380\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 381\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 382\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 383\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 384\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 385\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 386\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 387\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 388\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 389\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 390\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0023\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 391\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 392\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 393\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 394\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0026\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 395\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0024\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 396\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 397\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0011\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 398\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 399\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 400\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 401\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 402\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 403\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 404\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 405\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 406\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 407\n",
            "Training loss (for one batch) at step 0: 0.0022\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 408\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 409\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 410\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 411\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 412\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0011\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 413\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 414\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 415\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 416\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 417\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 418\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 419\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 420\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 421\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 422\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 423\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 424\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 425\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 426\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 427\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 428\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 429\n",
            "Training loss (for one batch) at step 0: 0.0021\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 430\n",
            "Training loss (for one batch) at step 0: 0.0008\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 431\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 432\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 433\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 434\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 435\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 436\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 437\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 438\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 439\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0028\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 440\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0022\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 441\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0011\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 442\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 443\n",
            "Training loss (for one batch) at step 0: 0.0019\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 444\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 445\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 446\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 447\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 448\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 449\n",
            "Training loss (for one batch) at step 0: 0.0018\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 450\n",
            "Training loss (for one batch) at step 0: 0.0017\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 451\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0021\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 452\n",
            "Training loss (for one batch) at step 0: 0.0023\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 453\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 454\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 455\n",
            "Training loss (for one batch) at step 0: 0.0020\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 456\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 457\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 458\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 459\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 460\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 461\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 462\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0010\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 463\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 464\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 465\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 466\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 467\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 468\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 469\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 470\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 471\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0018\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 472\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 473\n",
            "Training loss (for one batch) at step 0: 0.0009\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 474\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 475\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0019\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 476\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 477\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 478\n",
            "Training loss (for one batch) at step 0: 0.0012\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 479\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 480\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 481\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 482\n",
            "Training loss (for one batch) at step 0: 0.0009\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0016\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 483\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 484\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 485\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 486\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0013\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 487\n",
            "Training loss (for one batch) at step 0: 0.0008\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 488\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0015\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 489\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0020\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 490\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 491\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 492\n",
            "Training loss (for one batch) at step 0: 0.0013\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 493\n",
            "Training loss (for one batch) at step 0: 0.0010\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 494\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0012\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 495\n",
            "Training loss (for one batch) at step 0: 0.0016\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 496\n",
            "Training loss (for one batch) at step 0: 0.0014\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 497\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0017\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 498\n",
            "Training loss (for one batch) at step 0: 0.0011\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0010\n",
            "Seen so far: 120 samples\n",
            "\n",
            "Start of epoch 499\n",
            "Training loss (for one batch) at step 0: 0.0015\n",
            "Seen so far: 20 samples\n",
            "Training loss (for one batch) at step 5: 0.0014\n",
            "Seen so far: 120 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(trainMSE)\n",
        "plt.plot(testMSE)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('batch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(NormGrad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "OPlnVL5ZSmZ5",
        "outputId": "af0f62af-750b-40c7-bb48-5860b4628510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxddZ3/8dfnLtmTLmm6ptCyt2UtbQFXEISyCDo4LAqOo1J/o/hjxpEBRkXUGUX5qejIYlVkEAdEGGdQqpSlFZS1QFnaUpou2HRLmjZN2qz33s/vj3uS3qRZmpKTm+a+n49HHjnL957zyUlyP/f7/Z7z/Zq7IyIiuSuS7QBERCS7lAhERHKcEoGISI5TIhARyXFKBCIiOS6W7QAGaty4cT5t2rRshyEiclB56aWXtrt7RU/7DrpEMG3aNJYtW5btMEREDipm9nZv+9Q0JCKS45QIRERynBKBiEiOO+j6CHrS3t5OdXU1LS0t2Q4ldAUFBVRWVhKPx7MdioiMECMiEVRXV1NaWsq0adMws2yHExp3p66ujurqaqZPn57tcERkhBgRTUMtLS2Ul5eP6CQAYGaUl5fnRM1HRIbOiEgEwIhPAh1y5ecUkaEzYhJBf1rak2zd1UJ7MpXtUEREhpWcSgQ1jS0kU4M//0J9fT233377gF933nnnUV9fP+jxiIgMRM4kgo4GlTDm4ektESQSiT5ft2jRIkaPHj34AYmIDEBoicDM7jKzGjN7o59yc80sYWYfDSsWgGSQAVrak4N+7Ouvv561a9dy4oknMnfuXN773vdy4YUXMnPmTAA+/OEPc/LJJzNr1iwWLlzY+bpp06axfft2NmzYwIwZM7jqqquYNWsWZ599Ns3NzYMep4hIT8K8ffRu4MfAPb0VMLMo8B1g8WCd9Ou/W8HKzQ37bG9NJEkknUjEKIxHB3TMmZPL+NqHZvW6/+abb+aNN95g+fLlLF26lPPPP5833nij8xbPu+66i7Fjx9Lc3MzcuXO5+OKLKS8v73KMNWvWcN999/HTn/6USy65hIceeogrrrhiQHGKiByI0GoE7v4UsKOfYl8AHgJqwoojG+bNm9flPv8f/ehHnHDCCZx66qls3LiRNWvW7POa6dOnc+KJJwJw8skns2HDhqEKV0RyXNYeKDOzKcBHgDOAuf2UXQAsADjkkEP6PG5vn9zfrtvDruZ2CuJRjppQeiAh77fi4uLO5aVLl/L444/z7LPPUlRUxOmnn97jcwD5+fmdy9FoVE1DIjJkstlZfCtwnbv3ez+nuy909znuPqeiosfhtLOqtLSUxsbGHvft2rWLMWPGUFRUxJtvvslzzz03xNGJiPQtm0NMzAHuDx6QGgecZ2YJd/+fME8axuNY5eXlvPvd7+bYY4+lsLCQCRMmdO6bP38+d955JzNmzODoo4/m1FNPDSECEZEDZx7G/ZQdBzebBvze3Y/tp9zdQbkH+zvmnDlzvPvENKtWrWLGjBl9vq6pNUFV7W4qxxQxtjivv9MMa/vz84qIZDKzl9x9Tk/7QqsRmNl9wOnAODOrBr4GxAHc/c6wztubSCRdF4hohAYRkS5CSwTufvkAyn4yrDhERKRvOfNksYiI9EyJQEQkxykRiIjkOCUCEZEcp0QwCA50GGqAW2+9laampkGOSERk/ykRDAIlAhE5mI2IyeuzLXMY6g9+8IOMHz+eBx54gNbWVj7ykY/w9a9/nT179nDJJZdQXV1NMpnkq1/9Ktu2bWPz5s2cccYZjBs3jiVLlmT7RxGRHDTyEsEfroetr++zOc+dw9qSFMQjEBlgRWjicXDuzb3uzhyGevHixTz44IO88MILuDsXXnghTz31FLW1tUyePJlHHnkESI9BNGrUKL7//e+zZMkSxo0bN7CYREQGiZqGBtnixYtZvHgxJ510ErNnz+bNN99kzZo1HHfccTz22GNcd911PP3004waNSrboYqIACOxRtDLJ/f29iTrtjVyyNgiRheFN9aQu3PDDTfw2c9+dp99L7/8MosWLeIrX/kKZ555JjfeeGNocYiI7K+cqxGEMcRe5jDU55xzDnfddRe7d+8GYNOmTdTU1LB582aKioq44ooruPbaa3n55Zf3ea2ISDaMvBpBFmQOQ33uuefysY99jNNOOw2AkpIS7r33Xqqqqrj22muJRCLE43HuuOMOABYsWMD8+fOZPHmyOotFJCtCHYY6DAc6DHVre5LV2xqZOraIMSE2DQ0FDUMtIgPV1zDUOdc0JCIiXeVcIkimDq4akIhI2EZMIui3iSuYkGZz/cE9KfzB1pQnIsPfiEgEBQUF1NXVjfg3SXenrq6OgoKCbIciIiPIiLhrqLKykurqampra3stk0im2NbQCsCqxsKhCm3QFRQUUFlZme0wRGQECXPO4ruAC4CaniavN7OPA9eRbrRpBP7B3V89kHPF43GmT5/eZ5m/1jXxoXvTt2duuPn8AzmNiMiIFGbT0N3A/D72rwfe7+7HAd8EFoYYC6ZJ60VEehTm5PVPmdm0PvY/k7H6HBBqe0dqhPcfiIgcqOHSWfxp4A+97TSzBWa2zMyW9dUP0Jc9rckDjU1EZETLeiIwszNIJ4Lreivj7gvdfY67z6moqBi64EREckBW7xoys+OBnwHnuntdmOfyUIabExE5+GWtRmBmhwD/DVzp7m9lKw4RkVwX5u2j9wGnA+PMrBr4GhAHcPc7gRuBcuB2S9/Sk+htQCQREQlPmHcNXd7P/s8Anwnr/N0V1iznltid3JK4dKhOKSJyUMh6Z/FQie/exN/GnmK07c52KCIiw0rOJIKUpSs/MZIjfkwiEZGByJlEgEUBiJJCeUBEZK+cSQQdNYI4Cd1IKiKSIWcSgUcyawRKBSIiHXImERQXpsfwj1kSTVImIrJXziSCCaNLgKBGoMYhEZFOOZMIiGTeNZTlWEREhpEcSgQdfQRKBCIimXIoEXTUCNQ0JCKSKecSgWoEIiJd5VwiiJHSbGUiIhlyKBGk+whieqBMRKSLHEoEQdOQaYgJEZFMOZQI4kD69tGNO5qyHIyIyPCRQ4mgo7M4xcd/9nyWgxERGT5yKBF09BEk2dXcnuVgRESGjxxKBHtvHxURkb1yLhHESGU5EBGR4SW0RGBmd5lZjZm90ct+M7MfmVmVmb1mZrPDigVQjUBEpBdh1gjuBub3sf9c4MjgawFwR4ixdCaCuBKBiEgXoSUCd38K2NFHkYuAezztOWC0mU0KKx4iERwjakoEIiKZstlHMAXYmLFeHWzbh5ktMLNlZrastrb2gE+Yspj6CEREujkoOovdfaG7z3H3ORUVFQd8nJRF1UcgItJNNhPBJmBqxnplsC00KYuqRiAi0k02E8HDwCeCu4dOBXa5+5YwT5iymGoEIiLdxMI6sJndB5wOjDOzauBrQBzA3e8EFgHnAVVAE/D3YcXSIV0jUCIQEckUWiJw98v72e/A58M6f4/ntChRNQ2JiHRxUHQWD5aURYn3cfvoS2/v0MikIpJzQqsRDEdJyyOP3gecu/iOZwHYcPP5QxWSiEjW5VSNIBmJk0ci22GIiAwrOZUIEv3UCEREclFOJYJ0jSCdCBLJ3juN19buHqqQRESyLrcSgcXJt3Qi+LdHVrF++54eyz25qmYowxIRyaqcSgSJSH5nH8Hdz2zgjP+3NLsBiYgMAzmVCJIWVx+BiEg3uZUIInm6a0hEpJscSwR7+whERCQtpxJBwvQcgYhIdzmWCPLIpy3bYYiIDCs5lQj0ZLGIyL5yKhGkbx9VH4GISKacSgRJixM11+Q0IiIZcioRJCJ5AP3WChwfinBERIaFnEoESYsDkK/mIRGRTjmVCNoi+QAU9nPnkGFDEY6IyLAQaiIws/lmttrMqszs+h72H2JmS8zsFTN7zczOCzOe9mgxAEXWEuZpREQOKqElAjOLArcB5wIzgcvNbGa3Yl8BHnD3k4DLgNvDigfgrBMPB6CE5j7LqY9ARHJJmDWCeUCVu69z9zbgfuCibmUcKAuWRwGbQ4yH4pJRABRZa5inERE5qIQ5Z/EUYGPGejVwSrcyNwGLzewLQDFwVojxQF4J0H+NQH0EIpJLst1ZfDlwt7tXAucBvzSzfWIyswVmtszMltXW1h742YJEUIT6CEREOoSZCDYBUzPWK4NtmT4NPADg7s8CBcC47gdy94XuPsfd51RUVBx4RPlBjUCdxSIincJMBC8CR5rZdDPLI90Z/HC3Mn8FzgQwsxmkE8E7+Mjfjx6ahqpqND+xiOS20BKBuyeAq4FHgVWk7w5aYWbfMLMLg2L/DFxlZq8C9wGfdPfwbtnJK6bVY4yxvW/+Z33/T6GdTkTkYBBmZzHuvghY1G3bjRnLK4F3hxlDF2bUUcZYGrps/sx/vsjP/m7ukIUhIjKc7FeNwMyuMbMyS/u5mb1sZmeHHVwYdngZ5dY1ETy+qiZL0YiIZN/+Ng19yt0bgLOBMcCVwM2hRRWiHV66TyIQEcll+5sIOm6sPw/4pbuvyNh2UNnOqH2ahkREctn+JoKXzGwx6UTwqJmVAqnwwgrP/tQINMSEiOSS/e0s/jRwIrDO3ZvMbCzw9+GFFZ4dXkaxtVJAKy3kZzscEZGs298awWnAanevN7MrSA8Wtyu8sMJTS3q8oXHWe/gaYkJEcsn+JoI7gCYzO4H0vf9rgXtCiypEW30sABPZkeVIRESGh/1NBIngQa+LgB+7+21AaXhhhWebjwFgou3ssr2mYe+wE+ojEJFcsr99BI1mdgPp20bfGwwMFw8vrPBsDRLBhG6J4PP/9XI2whERybr9rRFcCrSSfp5gK+kB5G4JLaoQNVBMi8f3SQQNzYnOZfURiEgu2a9EELz5/woYZWYXAC3uflD2EYCx1cfukwjUHCQiuWp/h5i4BHgB+FvgEuB5M/tomIGFaRtjmGhdO4szh7pTUhCRXLK/fQRfBua6ew2AmVUAjwMPhhVYmLb5GI6zdV226a1fRHLV/vYRRDqSQKBuAK8dVh79x/exzccEdw3tffvPHP1afQQikkv2t0bwRzN7lPScAZDuPF7UR/lh6+iJpTzgYyi0NspoooFiQDUCEcld+5UI3P1aM7uYvXMHLHT334YXVrhqMm4hbfB0IlAmEJFctd8T07j7Q8BDIcYyZDqeLp5gO1njlYDygIjkrj4TgZk10vN7pAHu7mWhRBWybXQ8Xbz3zqEwZ8gUERnO+kwE7n5QDiPRn45hJsaz91mCzDSg20dFJJeEeuePmc03s9VmVmVm1/dS5hIzW2lmK8zsv8KMp8PD/3gW9V7cZbyht+uahuLUIiLDTmiT15tZFLgN+CBQDbxoZg8HE9Z3lDkSuAF4t7vvNLPxYcWT6eiJpbzZw9PFnXHp9lERySFh1gjmAVXuvs7d24D7SY9emukq4DZ33wnQ7VmFUBWVT2GCaShqEZEwE8EUYGPGenWwLdNRwFFm9hcze87M5vd0IDNbYGbLzGxZbW3toASXKpnEBKvvcZ/6CEQkl2T76eAYcCRwOnA58FMzG929kLsvdPc57j6noqJiUE7cWjieCuqJHJxTL4uIDJowE8EmYGrGemWwLVM18LC7t7v7euAt0okhdC2FE4hZinE9zLipPgIRySVhJoIXgSPNbLqZ5QGXAQ93K/M/pGsDmNk40k1F6xgCLQXpmkVvHcYiIrkitETg7gngauBRYBXwgLuvMLNvmNmFQbFHgTozWwksAa5197qwYsrUUjgRYJ/hqEF9BCKSW0K7fRTA3RfRbXA6d78xY9mBLwZfQ6q1IH2nqmoEIpLrst1ZnDVtheUk3XpMBOojEJFckrOJwCxGLaOZwL6JQE1DIpJLcjgRwFbfd8rKDjv3tPGxnz5HTUPLEEcmIjK0cjcRkJ6XYHwvD5Xd/+JGnllbx8//sn5oAxMRGWK5mwgMNns5k2073UfaVh+BiOSSnE0EYFR7BWXWzCj2dNmjPgIRySU5mwjMYKOnHyqbal3HukspD4hIDsnZRACw0dPPEky1wRnITkTkYJSzicDITARdawQ3/+FNVm9tyEJUIiJDL3cTgRmNFFHvxT3WCJ5fr7kKRCQ35G4iCL5v9IoeE0HmfUN1u1v51qJVJJIaslpERp7cTQTBO/1GH79P0xDA5l17HyS78eEVLHxqHU++OWQTqImIDJmcTQRzp4+lckwha30yh9o28mjvuaBDeyJdE0i5bicSkZEnZxNBWUGcP1/3AdakKolZium2pcdyr/y1vrP2ICIyEuVsIuiw2isBONqqe9y/pqaxc1kVAhEZiXI+Eaz3SSQ8wpGRnhPBzqZ2NtU393mMx1duY9UW3W4qIgenUCemORi0EWeDT+Ro29hrmbrdbX0e4zP3LANgw83nD2psIiJDIedrBPcvOJXVXsmRvTQNZVLLkIiMRDmfCE49rJw1XsmhVkM+fX/yFxEZiUJNBGY238xWm1mVmV3fR7mLzczNbE6Y8fRmdWoqEXOOsE097u/oJHaHh1/drAfLRGRECS0RmFkUuA04F5gJXG5mM3soVwpcAzwfViz9eSu4c+ioXpqHOoalXvT6Fv7vfa9wx9K1PZZ7Y9OucAIUEQlRmDWCeUCVu69z9zbgfuCiHsp9E/gOkLU5Id/2CbR6jBmRv/ZZrm5PKwDbGnsO9YL/+POgxyYiErYwE8EUIPNWnOpgWyczmw1MdfdH+jqQmS0ws2Vmtqy2dvCHjE4QY7kfwbzIqj7LdcxcpucJRGQkyVpnsZlFgO8D/9xfWXdf6O5z3H1ORUXFoMfy7x85lmdTMznO1lPWbbYygG0N6ZpAxxPGygMiMpKEmQg2AVMz1iuDbR1KgWOBpWa2ATgVeDgbHcYfP+VQnknOImrOvMib/ZZXjUBERpIwE8GLwJFmNt3M8oDLgIc7drr7Lncf5+7T3H0a8BxwobsvCzGmXi33I2j2PN4VWdFrmWfW1gVLygQiMnKElgjcPQFcDTwKrAIecPcVZvYNM7swrPMeqDbivJg6mtP6SAQdVCMQkZEk1CEm3H0RsKjbtht7KXt6mLHsj2dTs7gufj/j2MV2RvVaTolAREaSnH+yuMPRE0p5JpV+zKG/WoGraUhERhAlgsADnz2Nr171MRq8kNMiK/ssqxqBiIwkSgSBUUVx5hxWwQupYziln+cJlAdEZCRRIujmudRMDo9sYTw7ey3TV41gXe3uEKISEQmPEkE3z6VmAHBqH81DffURfOB7f2JXcy/zH4uIDENKBN2s9Gns8BLOiC7vtUxzW7LPY/S3X0RkOFEi6CZFhCdTs/lA5BViJHoss3136xBHJSISHiWCHjyWnM0oa2JO5K0e97+4YSeLV2zF+7l96IqfPc8/3v9KGCGKiAyanJ+zuLuH/uFdXHlHC60e57zI8zyX2mcKBQAW/PIlAN5zxLh99nUMTvfnqu0A3HrZSeEEKyIyCFQj6KaiJJ8mCvh96hT+Jvp0j6ORZup4sxcROVgpEXTT8Wn+54nzKLEWPhFdnN2ARERCpkTQi5U+jaXJE/h47AkiDHyO4q279s5i9sL6HRzz1T9Q39Q2mCGKiAwKJYJu8uN7L8l9yTOYZDt4X+TVAR3DgC/c93Ln+m1LqmhpT/HKxvrBClNEZNAoEXQzvrSgc/nJ1Gy2exmXR5cM7CAGze09PEugsSlEZBhSIuhBRWk+AI/80wf4TfL9nBl5mYnU9fOqrjrmN4bMKS6VCURk+FEi6EM8GuFXyTOJ4FweG1itwCxjeZDjEhEZTEoEPSgtSD9eETWj2sezNHUCl0ef7PVJ457ozV9EDhZKBD2451Pz+OoFMxlflm4i+mXyg4y3er4Wu4d8dOePiIwsoSYCM5tvZqvNrMrMru9h/xfNbKWZvWZmT5jZoWHGs78qxxTx6fdM71xfmjqBR5LzuDL2ON+M/aL/A/TSFdAxIsXdf1nPDx7refgKEZGhFloiMLMocBtwLjATuNzMuo/X8Aowx92PBx4EvhtWPO+EE+Hz7dfwq8SZXBx9iqm2rZ/ydOkksGC5IxHc9LuV/PCJNSFFKyIyMGHWCOYBVe6+zt3bgPuBizILuPsSd28KVp8DKkOM5x0yfpj4G5JE+Ex0UZ8l3bv2Eai/QESGszATwRRgY8Z6dbCtN58G/tDTDjNbYGbLzGxZbW3tIIbYN+v2Dl7DGH6bfC+XRpcyhd7jcHyf14qIDFfDorPYzK4A5gC39LTf3Re6+xx3n1NRUTFkceVFI3z2/Yd12fbDxN/gGP8a/1Wvrzvt20/yxqZdnetPvFkTWowiIu9UmIlgEzA1Y70y2NaFmZ0FfBm40N2H1YwvZsYN587oXD975gQ2M47bEhdxfvSFPoeeaE/u22Osx8lEZDgKMxG8CBxpZtPNLA+4DHg4s4CZnQT8hHQSGLYfm/OiEaaVF3W+kS9MXsC61ES+Ff85E9ix38fpbyIbEZFsCC0RuHsCuBp4FFgFPODuK8zsG2Z2YVDsFqAE+I2ZLTezh3s5XFat+uZ8nvjn0zvv+mkjzjXtVzOa3dyb923G0pDdAEVE3oFQZyhz90XAom7bbsxYPivM8w+WaKTj9s+9n+hf98P4TPuXuDv+HX6S930ubbuRVD95VfUBERmOhkVn8cGi+xv5c6mZXNd+FXMjb/GV2L1YP/MWqGVIRIYjJYIByKwRzJs2FoDXx57DLxLn8KnYH/lx/EdE6WH46cC1v3mVzfXNoccpIjIQSgQD0JEGfvHJuUwclZ63oC2Z4uuJT/Ct9ss5P/oC340vZDSNPb6+sTXBu25+cr/P93r1Lnbu0dhGIhIuJYIBSHVkAoOg24BL5kwFjIXJD3Fb4kIujj7Nk/n/zOG2z52yA/ahH/+Zv7njmXd8HBGRvigRDMB7jigH4JCxRXz+jCOYPq6YK089lA03n8+JU0dzS+JSFsS/RZIIP41/j3J29Xm8adc/QirlpFLO7taeh7hev33PoP8cIiKZQr1raKS56r2HcdGJU5hQlm4WWvKl0zv3/fqzp7JxRzOxiPF/vtfKvXnf5ld53+Lq9i9Q5b0PoZRIOT94/C3uWLqWN75+DiX5+pWIyNBSjWAAzKwzCXSXH4tyxPgSSgpivORH8+n2LzHVang8/1/4buwnvd5RdNRX/sDPnl4HwJ5eagUiImFSIhhk40rSk9k8kzqW01t/wMLE+VwS+xP/FvtFr3cUdQxHUb2zmcaW9iGLVUQElAhCtSs6luP//kfcmbiAj8ee4PG8LzHX3uy1/MV3PMNxNy3m+XV1QxiliOQ6JYIQpdyZMWkUNycu5/Nt/5cYKX6d901uid3Z511Fly58jlRq7zMLdyxdSyLZ98NqIiIHSokgRP/9uXcxqijOR06q5JHUqZzT9h3uSs7n/OjzLMq7gX+K/abX2c4O+9e9I3N8549vcs39y7vs39bQwtra3aHGLyK5QYkgRMdXjgbgB5eeCEATBfxb4kre23orf0zN45rYb1ma90W+FPs1cfruKH7k9S20JfbWCk751hOc+b0/AbByc4NGNhWRA6ZEkAV1jOKa9qt5f+v3eTD5fq6O/S8v5X+Wb8buCpqMen5TP/nfHuN3r27mO3/c28/wwLKNnPejp/nNsmoAbltSxftvWTIUP4aIjBC6aT1L/v0jxzJv2vt4fNXpXP3UQ5zR/icuiy7hytjjbPJy/pQ8np8kP8TbPrHzNY0tCb5w3ytdjvMvD74GwEtv7+SSuVO55dHVQ/pziMjBT4kgBO87qoKn3uo6p/ER40uoqtnbph+PRjhyQilHTiiF0/+FC/7jNP7fpvWcHl3OeyKvc1H0GT4afYqnU8fzaupwnkjNZoUfCvQ8GfKvl23knz54VOf6W9saOWpCaSg/n4iMLHawtS3PmTPHly1blu0w+uTuuEMk0vVNu6U9yQ8ee4ufPLWOO6+YzfxjJ3Xuu/sv67npdys71yuo5+rYbzkl8iZHWTURc9akpvBi6ig2+ESWpE6iyifjfbTu3fHx2eTHI9TtbuPG/13B6zedTSyq1kCRXGRmL7n7nB73KREMrZb2JP/zyiYunTsVs72J4ud/Xs83f7+yx9eMYxdnRV/iw9G/cIRtYpylZ0Tb7QVs8XJWeyVvpaay2itZ7VP5q0/odZKcfz3vGO5/cSML3nsY1//363z1gpkU5UW5rFs8HVIppyWRpChPlUeRg5kSwUHghfU7uOQnz7LwypOZNKqQD/34z132z502hm9++FiK82Jc+t3f8K7oCmbZBqbYdo6yag6xGiKW/l02ex6v+WG8mjqcKp/MhtREqr2CGkaT6KU1MBYxEsGzC6/fdDYph1GFcebf+hRvbm1k5TfOecfJoLaxle27W5kxqewdHUdEBk6J4CBR39TG6KI8ADbVNzOuJI9HXtvCFx94lXs+NY/3HVUBwEnfWMzOpq5DURTSwhG2maMjG5lpbzM7soYZ9lfyrWu57V5GlU+hxkez00vY6uVs8nI2ezlbGUu9l7CHgh6bnArjUY6dUsbtHz+ZiMHm+hYAFq/cysYdTRxfOZqZk8s4oXI0hXnRfV5/3E2P0tiSYMPN5w/K9RKR/Ze1RGBm84EfAlHgZ+5+c7f9+cA9wMlAHXCpu2/o65gjORHsr9uXVvHdP67mc6cfzu1L1/K1D83kA8eM5/23LCU/FqE1eN4gRoJJVsd028ok28FEdjDJ6jgysokxNDLWGhlt+w5znfAIOymhzkexw0upp4RdXswuimnwYuopYaeX0EgRTZ7PHgrYQwFtHqedKO3EaCO97ESYNbmMFZsbOo9/7rETmTW5jMdWbuPV6l18+j3TmTttDEdNKKUwL0pxfoyygjib65sZU5RHYV6UZMppS6TIj0WIRIyqmkaOGL+3M7yhpZ2ygnjn+o49bUQjxqjCOPujPZkikfQeE9iB2tOaIC8WId5Hv8ziFVspyovxniPHDdp5RXqSlURgZlHgLeCDQDXwInC5u6/MKPM54Hh3/z9mdhnwEXe/tK/jKhFAWyLFPc9u4JPvmtZj528y5aze2siS1TVcPLuSU7/9BAAvfvks5v774wBcOmcqv162kSJamGzbmWx1TLCdjGIPo2wP5TRQbg2MtQZGsYfRtodR7NmnhtGfdu9IDLG93z3W5xheCagAAAx7SURBVLaO7X1ta+1Y7zhGsN0xHILvRirjOxhJIqQwUkRIeqRzfwfvdleWYySIkgpe1+GYSWUcPaGM5dX1tCbSgwnW7WlnYlkB6+uaKc2P0diawIELjp/Eqi2N5Mej1De1UTmmmB1NrRwzsYzfvboZw7n05CmUFMSoqtnNzEll1O5u45m1dZx2+Lj0UCUTS1n49AZqd7cCcNIhozn32Ems295EaUGM5rYk8WiEpEM0EuHdR5RTt7uN9XVN/OIvGzihchSnHV5BcX6U8pJ8dja189Rbtcw/bhKplDNlTCFNbUmSKWfLrhYmjiqgbncrre0pllfv5G9PrmTLrmZK8uMU50eJmFG9o5maxla+/3gV7z5sDF8480hGFcb53+WbmDS6iEg0yqLXt3LB8ZPZvruV7y1+i598Yg4VpfnUNLSwoynB7ENGs6c1QUlBnLZkCncoyY+mf1ep9AeaprYkze1Jxpfm05Jwduxpo6axlVmTy0iknAiWjqe+iSljiohFI7S2J2lpT9GaSEAqhaUStCaSHDV5LFW1ezi0vKTzaZ10wk5/AIjHIsQiUZrbEzQ0t7NuexN5sQjHTCyjIB4jHjWaE+k4i/KiuBuRSHo+8obmNprbE7QnkrxeXc8HjhlPPBbHzDAzWpNOTUML5SX5FOVFMEv/77o7ZkYimeKxVbWcPWsC0aC/riPG9qTT3J4kEsujtKRkQP+DHbKVCE4DbnL3c4L1GwDc/dsZZR4NyjxrZjFgK1DhfQSlRDBwG3c00dKe5MgJpfylajubdjZzydyptCaStCVSlBbE2bqrhZv/sIr/Wb4ZgJ9+Yg6nHV7Oc2vr+Mw9e693Pm2MZjdjbDfFNFNiLRTRQrG1kEeCePDVsZxn7cRJ9rAtQV6wvf9tic5jxK33OaFFRroXpnyCeVf9xwG9NluJ4KPAfHf/TLB+JXCKu1+dUeaNoEx1sL42KLO927EWAAsADjnkkJPffvvtUGKW9Kej4m6T43TcDttxU1Ht7lbGl6bnZdhc38ykUQW0BYPi5ce6Nq1s2dVM3e42CuIRNu5opi2Z4pTpY9m+u5U3tzYyZXQhb9c1cXhFCVPHFtKWTNHanuInT62loTnBtHHFrNnWSOWYQsyMKCnG5Btv19azbusOjp9czLgCZ/OOBlLtrayr2c2Esnx27mmlfk8rY4rj1Oxqpjg/ylEVRTS3tbO+ppGopesC0WCeiFhk7ydQCz6HFeVFaWlLECFFjGSXegPAkeOLqarZ0+U1lvFUuAGVYwqp3tnc4/6OMqmMmkvXY+1VGI/Q0p7s3F9ekseO3ZnzWXc9fml+rMusd73F1z0Yw8mPR2lp6zrI4biSPGp37zt/dsTSda+URzhiQgk797SzfXcrEXMiwbUdU5RHa3v6U31FSR7NbUmK86PUNLbuPQ5OXjRCXjxCaX6Mgnj6b3BD3R5Snt7n7ukagKWnjS2MGy3t6XMcM7GM1Vt3UZQXY970sSxdXdN57CQREkSZUJrPxJIoq7Y0ML40j6MnlJJyeL26nsbWBPGoUVGcR3FBjJL8GK9u3Nl5jJmTSlm1pZHRhTF2NadrxcdPKWPjziamlRezvnY3BXkxtjS0UZAXpSgvxqzJZdQ1tJDyFG2JJG/XNQFQUZrHjInpcyfdaWhuZ9POZiaU5VPb2MIxE8vY2tBCS1uCI8aX0pZM8cL6HYwqjHP2B+dz9Cnn7vN72B8HfSLIpBqBiMjA9ZUIwny6aBMwNWO9MtjWY5mgaWgU6U5jEREZImEmgheBI81supnlAZcBD3cr8zDwd8HyR4En++ofEBGRwRfa46LunjCzq4FHSd8+epe7rzCzbwDL3P1h4OfAL82sCthBOlmIiMgQCnXcAHdfBCzqtu3GjOUW4G/DjEFERPqmEchERHKcEoGISI5TIhARyXFKBCIiOe6gG33UzGqBA320eBzQ68NqWTRc44LhG5viGhjFNTAjMa5D3b2ipx0HXSJ4J8xsWW9P1mXTcI0Lhm9simtgFNfA5FpcahoSEclxSgQiIjku1xLBwmwH0IvhGhcM39gU18AoroHJqbhyqo9ARET2lWs1AhER6UaJQEQkx+VMIjCz+Wa22syqzOz6LJx/g5m9bmbLzWxZsG2smT1mZmuC72OC7WZmPwpifc3MZg9iHHeZWU0wKVDHtgHHYWZ/F5RfY2Z/19O5BiGum8xsU3DNlpvZeRn7bgjiWm1m52RsH9Tfs5lNNbMlZrbSzFaY2TXB9qxesz7iyuo1M7MCM3vBzF4N4vp6sH26mT0fnOPXwdD0mFl+sF4V7J/WX7yDHNfdZrY+43qdGGwfsr/94JhRM3vFzH4frA/t9UpPQziyv0gPg70WOAzIA14FZg5xDBuAcd22fRe4Pli+HvhOsHwe8AfSswmeCjw/iHG8D5gNvHGgcQBjgXXB9zHB8pgQ4roJ+FIPZWcGv8N8YHrwu42G8XsGJgGzg+VS4K3g/Fm9Zn3EldVrFvzcJcFyHHg+uA4PAJcF2+8E/iFY/hxwZ7B8GfDrvuINIa67gY/2UH7I/vaD434R+C/g98H6kF6vXKkRzAOq3H2du7cB9wMXZTkmSMfwn8HyfwIfzth+j6c9B4w2s0mDcUJ3f4r03A/vJI5zgMfcfYe77wQeA+aHEFdvLgLud/dWd18PVJH+HQ/679ndt7j7y8FyI7AKmEKWr1kfcfVmSK5Z8HPvDlbjwZcDHwAeDLZ3v14d1/FB4Ewzsz7iHey4ejNkf/tmVgmcD/wsWDeG+HrlSiKYAmzMWK+m73+aMDiw2MxeMrMFwbYJ7r4lWN4KTAiWhzregcYxlPFdHVTN7+pofslWXEE1/CTSnyaHzTXrFhdk+ZoFzRzLgRrSb5RrgXp3T/Rwjs7zB/t3AeVDEZe7d1yvfw+u1w/MLL97XN3OH8bv8VbgX4BUsF7OEF+vXEkEw8F73H02cC7weTN7X+ZOT9fvsn4v73CJI3AHcDhwIrAF+F62AjGzEuAh4B/dvSFzXzavWQ9xZf2auXvS3U8kPU/5POCYoY6hJ93jMrNjgRtIxzeXdHPPdUMZk5ldANS4+0tDed7uciURbAKmZqxXBtuGjLtvCr7XAL8l/Q+yraPJJ/heExQf6ngHGseQxOfu24J/3hTwU/ZWdYc0LjOLk36z/ZW7/3ewOevXrKe4hss1C2KpB5YAp5FuWumYETHzHJ3nD/aPAuqGKK75QRObu3sr8AuG/nq9G7jQzDaQbpb7APBDhvp6vZMOjoPli/SUnOtId6J0dIjNGsLzFwOlGcvPkG5XvIWuHY7fDZbPp2tH1QuDHM80unbKDigO0p+c1pPuLBsTLI8NIa5JGcv/RLoNFGAWXTvG1pHu9Bz033Pws98D3Npte1avWR9xZfWaARXA6GC5EHgauAD4DV07Pz8XLH+erp2fD/QVbwhxTcq4nrcCN2fjbz849uns7Swe0us1aG8uw/2L9F0Ab5Fur/zyEJ/7sOCX9CqwouP8pNv2ngDWAI93/EEFf3y3BbG+DswZxFjuI91k0E66HfHTBxIH8CnSHVJVwN+HFNcvg/O+BjxM1ze5LwdxrQbODev3DLyHdLPPa8Dy4Ou8bF+zPuLK6jUDjgdeCc7/BnBjxv/AC8HP/hsgP9heEKxXBfsP6y/eQY7ryeB6vQHcy947i4bsbz/juKezNxEM6fXSEBMiIjkuV/oIRESkF0oEIiI5TolARCTHKRGIiOQ4JQIRkRynRCDSAzObZhkjoe5H+U+a2eT9KPPjdx6dyOBSIhAZHJ8E+kwEIsOVEoFI72Jm9iszW2VmD5pZkZndaGYvmtkbZrYwGLf+o8Ac4FfBmPaFZjbXzJ4Jxr9/wcxKg2NONrM/BmPZfzeLP5tIJyUCkd4dDdzu7jOABtJjwf/Y3ee6+7Gkhyq4wN0fBJYBH/f0oGZJ4NfANe5+AnAW0Bwc80TgUuA44FIzm4pIlikRiPRuo7v/JVi+l/SwDmcEM0O9TnqAsFk9vO5oYIu7vwjg7g2+d0jhJ9x9l7u3ACuBQ8P9EUT6F+u/iEjO6j7+igO3kx53ZqOZ3UR67JeBaM1YTqL/QRkGVCMQ6d0hZnZasPwx4M/B8vZgHoCPZpRtJD1lJKQH/ZpkZnMBzKw0Y0hhkWFHf5wivVtNehKhu0g349xBeujhN0jPSvZiRtm7gTvNrJn0+PuXAv9hZoWk+wfOGsK4RQZEo4+KiOQ4NQ2JiOQ4JQIRkRynRCAikuOUCEREcpwSgYhIjlMiEBHJcUoEIiI57v8DAJ4eIqBx7VsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffa55301c10>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder=enc.numpy()\n",
        "encoder=encoder[0]\n",
        "#plt.plot(encoder)\n",
        "plt.hist(encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "SFmmKOhVTe4_",
        "outputId": "0043f4c9-2dc6-465e-9000-17a5105b59f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 4., 12.,  8., 14.,  6.,  6., 12.,  7.,  5.,  6.]),\n",
              " array([0.1102871 , 0.18842216, 0.26655722, 0.3446923 , 0.42282733,\n",
              "        0.5009624 , 0.57909745, 0.6572325 , 0.73536754, 0.8135026 ,\n",
              "        0.8916377 ], dtype=float32),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}